# EFA {#efa}

```{r, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, warning = FALSE, message = FALSE
)
```


```{r, include=FALSE}
library(data.table)
library(glue)
library(lavaan)
library(googlesheets4)
library(kableExtra)
library(psych)

questions <- fread('./data/questions.csv')
c2_data <- fread('./data/c2_data.csv')
questionnaire_names <- fread('./data/questionnaire_names.csv')

c2_info <- questionnaire_names[question_type == 'competencies']
c2_questions <- c2_info[order(q_order), question_ru]
c2_q_numbers <- c2_info[order(q_order), q]

c2_names <- questions[question_ru %in% c2_info[, unique(question_ru)], sort(unique(c2))]
c3_names <- questions[question_ru %in% c2_info[, unique(question_ru)], sort(unique(c3))]

fit_c3_mlr <- readRDS('fit_c3_mlr')
c3_models <- readRDS('c3_models')

fit_mlr_cleaned <- readRDS('fit_mlr_cleaned')
coeffs_cleaned <- data.table(parameterEstimates(fit_mlr_cleaned))[op == '=~']
coeffs_cleaned_lowp <- coeffs_cleaned[pvalue < 0.05 | is.na(pvalue)]
coeffs_cleaned[pvalue >= 0.05, .N]
```


## Размеры шкал

Основная проблема в модели на уровне с2-шкал --- неравномерность шкал по количеству вопросов. Эта неравномерность вызвана тем, что от исходной модели опросника на 230 вопросов в количественном исследовании было использовано всего 137 вопросов. Остальные вопросы (и, соответственно, (суб)шкалы), было решено оценивать акачественными методами.

В результате в некоторых шкалах всего 3 вопроса, а в некоторых --- до 27:

```{r}
scales_questions <- merge(
  # coeffs[, list(full_model = .N), keyby = lhs],
  c2_info[, list(full_model = .N), keyby = list(lhs = paste0('c', c2), C1, C2)],
  coeffs_cleaned_lowp[, list(trimmed_model = .N), by = lhs],
  by = 'lhs', all.x = TRUE
)
scales_questions[, excluded := full_model - trimmed_model]
setnames(scales_questions, 'lhs', 'c2')

kableExtra::kable(rbind(scales_questions[3:8], scales_questions[1:2])) %>%
  kable_styling(font_size = 12)
```


## Модель с3-шкал

Самый простой способ решить эту проблему -- оценить структуру опросника на уровне дробных с3-шкал. Это помогло бы оценить вклады тех или иных вопросов, или же просто расширить количество шкал опросника.

Однако модель на 30 факторов не сходится, даже если предположить скоррелированность латентных факторов.

```{r}
fit_c3_mlr
```

Если рассматривать каждую из 30 шкал отдельно, то видно, что есть несколько шкал, по которым даже маленькая модель сойтись не может. 

```{r}
c3_models_tbl <- lapply(1:length(c3_names), function(x) {
  result <- tryCatch(
      # as.data.table(as.list(c('c3' = c3_names[x], fitMeasures(c3_models[[x]], c("cfi", "rmsea", "srmr", "chisq", "df"))))),
      as.data.table(as.list(c('c3' = c3_names[x], round(fitMeasures(c3_models[[x]], c("cfi", "rmsea", "srmr")), 3)))),
    error = function(e) data.table(c3 = c3_names[x], cfi = NA, rmsea = NA, srmr = NA)
  )
  # print(result)
  result
})
c3_models_tbl <- rbindlist(c3_models_tbl)
c3_models_tbl <- merge(
  c2_info[, list(c2 = unique(c2), n_questions = .N), keyby = c3], 
  c3_models_tbl, 
  by = 'c3', all.x = TRUE
)
c3_models_tbl[, cfi := cell_spec(cfi, color = ifelse(cfi >= 0.9 | is.na(cfi), "black", "red"))]
c3_models_tbl[, rmsea := cell_spec(rmsea, color = ifelse(rmsea < 0.08 | is.na(rmsea), "black", "red"))]
c3_models_tbl[, srmr := cell_spec(srmr, color = ifelse(srmr < 0.08 | is.na(srmr), "black", "red"))]

kable(c3_models_tbl)
```

Как правило, такое происходит в нескольких ситуациях:

 - вопросы либо очень слабо, либо очень сильно скоррелированы
 - есть много пропусков или недостаточно респондентов
 - не учтена ситуация, когда один вопрос может в реальности относиться к нескольким факторам (кросс-нагрузки)

## EFA, с3 = 5

Я попробовал переразбить вопросы шкалы с2 = 5 (отношения-1) на две субшкалы. Для этого я использовал эксплораторный факторный анализ с oblimin-вращением. Вращение нужно, что сделать структуру более интерпретабельной, а также выровнять факторы, так как без вращения первый фактор всегда забирает максимум дисперсии и, соответственно, остальные факторы меньше по количеству вопросов и менее интерпретабельны.

```{r}
# fa_result <- fa(c2_data[, .SD, .SDcols = questions[c2 == 5 & question_ru %in% c2_questions, q]], nfactors = 2, rotate = "oblimin")
fa_result <- fa(c2_data[, .SD, .SDcols = questions[c2 == 5 & question_ru %in% c2_questions, q]], nfactors = 2, rotate = "oblimin")
print(fa_result$loadings, cutoff = 0.4)
```
Диаграмма, дисперсия каких вопросов каким фактором объясняется, выглядит вот так.
```{r}
fa.diagram(fa_result)
```

Таблица вопросов с маркером объясняющего их фактора:

```{r}
loadings_df <- as.data.table(round(unclass(fa_result$loadings), 3), keep.rownames = TRUE)
loadings_df[, factor_number := apply(as.data.frame(unclass(fa_result$loadings)), 1, function(x) which.max(abs(x)))]
loadings_df[abs(MR1) < 0.4 & abs(MR2) < 0.4, factor_number := NA]
setnames(loadings_df, 'rn', 'q')

loadings_df <- merge(
  questions[c2 == 5 & question_ru %in% c2_questions, list(C2, c2, c3, q, competence_ru, question_ru)],
  loadings_df,
  by = 'q', all.x = TRUE
)

kable(loadings_df[order(factor_number, c3), list(C2, c2, c3, q, competence_ru, question_ru, MR1, MR2, factor_number)]) %>%
  kable_styling(font_size = 12)
```

Вообще, большое количество вопросов, которые оказались без сильных нагрузок по первому или второму факторам, свидетельствует о том, что либо респонденты неверно понимают вопросы, либо эти вопросы служат маркерами какой-то иной компетенции.

```{r}
kable(loadings_df[, list(n_questions = .N), keyby = factor_number]) %>%
  kable_styling(font_size = 12)
```


## EFA, с3 = 10

Аналогично с с2 = 10 (профессионализм) на две субшкалы. 

```{r}
fa_result <- fa(c2_data[, .SD, .SDcols = questions[c2 == 10 & question_ru %in% c2_questions, q]], nfactors = 2, rotate = "oblimin")
print(fa_result$loadings, cutoff = 0.4)
```
Диаграмма, дисперсия каких вопросов каким фактором объясняется, выглядит вот так. Связь между факторами со значением 0.5 свидетельствует от достаточно сильной корреляции факторов друг с другом.
```{r}
fa.diagram(fa_result)
```

Таблица вопросов с маркером объясняющего их фактора:

```{r}
loadings_df <- as.data.table(round(unclass(fa_result$loadings), 3), keep.rownames = TRUE)
loadings_df[, factor_number := apply(as.data.frame(unclass(fa_result$loadings)), 1, function(x) which.max(abs(x)))]
loadings_df[abs(MR1) < 0.4 & abs(MR2) < 0.4, factor_number := NA]
setnames(loadings_df, 'rn', 'q')

loadings_df <- merge(
  questions[c2 == 10 & question_ru %in% c2_questions, list(C2, c2, c3, q, competence_ru, question_ru)],
  loadings_df,
  by = 'q', all.x = TRUE
)

# kable(loadings_df[order(factor_number, c3)])
kable(loadings_df[order(factor_number, c3), list(C2, q, competence_ru, question_ru, MR1, MR2, factor_number)]) %>%
  kable_styling(font_size = 12)
```

Здесь факторная структура и разделение вопросов по факторам также более сбалансировано:
```{r}
kable(loadings_df[, list(n_questions = .N), keyby = factor_number]) %>%
  kable_styling(font_size = 12)
```


## EFA, с3 = 11

Аналогично с с2 = 11 (результаты), попробовал разбить на две субшкалы. 

```{r}
fa_result <- fa(c2_data[, .SD, .SDcols = questions[c2 == 11 & question_ru %in% c2_questions, q]], nfactors = 2, rotate = "oblimin")
print(fa_result$loadings, cutoff = 0.4)
```
Диаграмма, дисперсия каких вопросов каким фактором объясняется, выглядит вот так. Связь между факторами со значением -0.4 свидетельствует от достаточно сильной отрицательной корреляции.
```{r}
fa.diagram(fa_result)
```

Таблица вопросов с маркером объясняющего их фактора:

```{r}
loadings_df <- as.data.table(round(unclass(fa_result$loadings), 3), keep.rownames = TRUE)
loadings_df[, factor_number := apply(as.data.frame(unclass(fa_result$loadings)), 1, function(x) which.max(abs(x)))]
loadings_df[abs(MR1) < 0.4 & abs(MR2) < 0.4, factor_number := NA]
setnames(loadings_df, 'rn', 'q')

loadings_df <- merge(
  questions[c2 == 11 & question_ru %in% c2_questions, list(C2, c2, c3, q, competence_ru, question_ru)],
  loadings_df,
  by = 'q', all.x = TRUE
)

# kable(loadings_df[order(factor_number, c3)])
kable(loadings_df[order(factor_number, c3), list(C2, q, competence_ru, question_ru, MR1, MR2, factor_number)]) %>%
  kable_styling(font_size = 12)
```

Здесь факторная структура и разделение вопросов по факторам оказалось более сбалансированным:
```{r}
kable(loadings_df[, list(n_questions = .N), keyby = factor_number]) %>%
  kable_styling(font_size = 12)
```